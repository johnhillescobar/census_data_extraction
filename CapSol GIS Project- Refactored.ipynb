{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import censusdata\n",
    "import openpyxl\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusdata.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### do the preliminary work\n",
    "\n",
    "* Open Excel file GIS_Census.xlsx  \n",
    "<br>\n",
    "* You are expected to change the data input. However, do not change column names and the order by which the parameters are displayed. Furthermore, do not write anything on the areas highlighted in gray.  \n",
    "<br>\n",
    "* In the \"parameters tab\", fill parameters according to your needs.  Nontheless, you must remember the following:  \n",
    "    \n",
    "    1. *If you are using \"acs1\" the summary level CANNOT be 140. \"acs1\" type is less granular, so 050 and 040 are the only levels available.*  \n",
    "    <br>\n",
    "    2. *You CANNOT mix certain table types, so you should download every type separately. For example, your \"logic tab\" CANNOT have at the same time the following attributes B25002_001E (a detail attribute from a detail table) and DP03_0001E (a detail attribute from a profile table) because the script will fail.*  \n",
    "    <br>\n",
    "    3. *Adjust parameter table according to the data type you are using. Options are ‘detail’ (detail tables), ‘subject’ (subject tables), ‘profile’ (data profile tables), ‘cprofile’ (comparison profile tables).*  \n",
    "    <br>\n",
    "    4. *Adjust your the \"Naming Friendliness\" parameter by using the most appropiate logic column name for your work.  For instance, a GIS analyst would be more interested in pulling data with \"GIS Name\" column names.  Options are ‘Schema Name’ (the census coded names), ‘Human Friendly Name’ (the human names assigned by the census bureau), ‘Mgr_Name’ (names assigned by the team of researchers), and ‘GIS_Name’ (names created by the GIS analyst to create a visualizations).*  \n",
    "    <br>\n",
    "<br>    \n",
    "* In the \"logic tab\", fill parameters according to your needs.  Nontheless, you must remember the following:  \n",
    "\n",
    "    1. *The \"logic tab\" MUST have NO data gaps.  This means that each schema name MUST have a human friendly name, mgr_name, a GIS_name and a description.  If you have no definition at hand, you should type down \"No Definition\".  This script uses this information not only to pull the data from the census bureau, but also to document the data search.  This script will delete ALL lines that are NOT complete.*\n",
    "<br>\n",
    "<br>\n",
    "* You can pull data until 2011. However, you should be aware that the census bureau work is dynamic, which means that attributes that are tracked in 2019 are NOT necessarily available in previous year.  The script will throw an error message when the attribute does NOT exist.  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "##### if  you are NOT sure about the table type you are dealing with    \n",
    "    \n",
    "The American Community Survey (ACS) provides four different sets of data tables:\n",
    "\n",
    "* **Detailed tables**. These provide the most detailed set of variables. Table names begin with B followed by a numeric code.  \n",
    "\n",
    "* **Data profile tables**. These tables are designed to provide information on a broad array of characteristics for a given geography. There are data profile tables on:  \n",
    "\n",
    "    1. Social Characteristics (DP02),\n",
    "    1. Economic Characteristics (DP03),\n",
    "    1. Housing Characteristics (DP04), and\n",
    "    1. Demographic Characteristics (DP05).  \n",
    "    \n",
    "  Table names (beginning in DP) are shown in parentheses above.  \n",
    "  \n",
    " <br>\n",
    "\n",
    "* **Subject tables**. These tables are designed to provide information on narrower topics for a broader range of geographies. Table names begin with S.\n",
    "\n",
    "* **Comparison profile tables**. These tables provide information on changes in characteristics in particular geographies over time, including statistical significance testing. Table names begin with CP.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "##### if  you are NOT sure about the summary level you are looking for \n",
    "\n",
    "This file only provides data for State, State-County and State-County-Census Tract.  To learn more bout the cartographic boundary file summary level, go visit:  \n",
    "<br>\n",
    "https://www.census.gov/programs-surveys/geography/technical-documentation/naming-convention/cartographic-boundary-file/carto-boundary-summary-level.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_list(file_name, folder= 'inputs', sheetname = 'states', skiprows = 5):\n",
    "    \"\"\"\n",
    "    This function creates a list of states numbers, which is used to process our\n",
    "    our census query\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # define path and data types\n",
    "    full_path = os.path.join(folder, file_name)\n",
    "    dtype = {'state_name': str, 'state_number': str}\n",
    "\n",
    "    # read the states list from the census index\n",
    "    state_list = pd.read_excel(full_path, sheet_name= sheetname, skiprows = skiprows, dtype = dtype)\\\n",
    "                              .dropna()    \n",
    "    \n",
    "    if state_list.shape[0] == 0:\n",
    "        \n",
    "        print(\"################################################################\")\n",
    "        print(\"\")\n",
    "        print(\"Number of rows: \", state_list.shape[0])\n",
    "        print(\"\")\n",
    "        print(\"Please, enter at least a value in GIS Census file's tab 'states'\")\n",
    "        print(\"\")\n",
    "        print(\"################################################################\")\n",
    "    \n",
    "    return state_list\n",
    "\n",
    "\n",
    "def params_tupple( file_name, folder= 'inputs', sheetname = 'parameters', skiprows = 7):\n",
    "    \"\"\"\n",
    "    This function stores the parameters used for the formater\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # define path and data types\n",
    "    full_path = os.path.join(folder, file_name)\n",
    "\n",
    "    # read the states list from the census index\n",
    "    params_tupple = pd.read_excel(full_path, sheet_name= sheetname, skiprows = skiprows)\\\n",
    "                              .dropna()    \n",
    "    \n",
    "    if (params_tupple.shape[1] <= 4) | params_tupple.shape[0] <= 1:\n",
    "        \n",
    "        #print(params_tupple)\n",
    "        \n",
    "        print(\"####################################################################\")\n",
    "        print(\"\")\n",
    "        print(\"####################  Parameter is missing  ########################\")\n",
    "        print(\"\")\n",
    "        print(\"Please, enter two parameters in GIS Census file's tab 'parameters'\")\n",
    "        print(\"\")\n",
    "        print(\"####################################################################\")\n",
    "        \n",
    "        acs = None\n",
    "        year = None\n",
    "    \n",
    "    else:\n",
    "        #params_tupple\n",
    "        acs = params_tupple.iloc[0,1].lower()\n",
    "        year = params_tupple.iloc[1,1]\n",
    "        sum_level = params_tupple.iloc[2,1]\n",
    "        frly = params_tupple.iloc[3,1]\n",
    "        table_type = params_tupple.iloc[4,1].lower()\n",
    "    \n",
    "    return acs, year, sum_level, frly, table_type\n",
    "\n",
    "\n",
    "def logic_tab(file_name, folder= 'inputs', sheetname = 'logic', skiprows = 2):\n",
    "    \"\"\"\n",
    "    This function procceses the data in the logic tab.  This data will be used to define the dictionaries\n",
    "    needed to give human or GIS friendly names to the resulting metadata\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # define path and data types\n",
    "    full_path = os.path.join(folder, file_name)\n",
    "    \n",
    "    # read the states list from the census index\n",
    "    logic_list = pd.read_excel(full_path, sheet_name= sheetname, skiprows = skiprows)\\\n",
    "                              .dropna()    \n",
    "    \n",
    "    if logic_list.shape[0] == 0:\n",
    "        \n",
    "        print(\"################################################################\")\n",
    "        print(\"\")\n",
    "        print(\"Number of rows: \", logic_list.shape[0])\n",
    "        print(\"\")\n",
    "        print(\"Please, you must fill ALL the information requested in the logic tab.\")\n",
    "        print(\"\\nOtherwise, no dataframe will be generated\")\n",
    "        print(\"\")\n",
    "        print(\"################################################################\")\n",
    "        \n",
    "    # define list of fields that will be pulled from the census\n",
    "    census_attributes = list(logic_list['Schema Name'])\n",
    "    \n",
    "    # create dictionaries to rename our dataframe's metadata\n",
    "    human_dict = dict(zip(logic_list['Schema Name'], logic_list['Human Friendly Name']))\n",
    "    mngr_dict = dict(zip(logic_list['Schema Name'], logic_list['Mgr_Name']))\n",
    "    gis_dict = dict(zip(logic_list['Schema Name'], logic_list['GIS Name']))\n",
    "    \n",
    "    \n",
    "    return logic_list, human_dict, mngr_dict, gis_dict, census_attributes\n",
    "\n",
    "\n",
    "def tract_formatter(df, sum_level):\n",
    "    \"\"\"\n",
    "    This function allows data analysts to get FIPS number out of the information provided by the given\n",
    "    dataframe index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #reset index to find numbers by using regular expressions\n",
    "    df.reset_index(inplace= True)\n",
    "    df.rename(columns= {'index': 'summary'}, inplace= True)\n",
    "    \n",
    "    # we need to format tracts in a FIPS form, assign numbers to state, county and tracts, as well as\n",
    "    # naming the states, counties, and tracts we are working with.  finally, we need to get rid of the columns\n",
    "    # we do not need. the following dictionary will help to do all of this in a few lines of code.\n",
    "    rename_dict = {140: {'tracts': {0:\"census_tract_no\", 1:\"summary_level\", 2:\"state\", 3:\"county\", 4:\"tract\"},\n",
    "                         'splits': {1:\"county_name\", 2:\"state_name\"},\n",
    "                         'cols':   [0, 3]},\n",
    "                   \n",
    "                   50: {'tracts': {0:\"summary_level\", 1:\"state\", 2:\"county\", 3:\"tract\"},\n",
    "                        'splits': {0:\"county_name\", 1:\"state_name\"},\n",
    "                        'cols':   [2]},\n",
    "                   \n",
    "                   40: {'tracts': {0:\"summary_level\", 1:\"state\"},\n",
    "                        'splits': {0:\"state_name\"},\n",
    "                        'cols':   [1, 2, 3]}}\n",
    "    \n",
    "    # extract the numbers assigned for summary level, state, county, tract and census tract\n",
    "    tracts = df['summary'].apply(lambda x: pd.Series(re.findall(r'[0-9]+\\.*[0-9]*',str(x)))\n",
    "                                 .rename(rename_dict[sum_level]['tracts']))\n",
    "        \n",
    "     \n",
    "    # with the information already extracted we can create our FIPS number by broadcasting the newly created\n",
    "    # columns\n",
    "    if sum_level == 140:\n",
    "        tracts['census_tract'] = tracts['state'] + tracts['county'] + tracts['tract']\n",
    "        \n",
    "    elif sum_level == 50:\n",
    "        tracts['census_tract'] = tracts['state'] + tracts['county']\n",
    "        \n",
    "    elif sum_level == 40:\n",
    "        tracts['census_tract'] = tracts['state']\n",
    "    \n",
    "    \n",
    "    # find human friendly names and drop columns you don't need\n",
    "    if (sum_level == 140) | (sum_level == 50):\n",
    "        splits = df['summary'].apply(lambda x: pd.Series(str(x).split(',')).rename(rename_dict[sum_level]['splits']))\n",
    "        splits[\"state_name\"] = pd.Series([i[0][:-1] for i in splits['state_name'].str.split()])\n",
    "        \n",
    "    else:\n",
    "        splits = df['summary'].apply(lambda x: pd.Series(str(x).split(':')).rename(rename_dict[sum_level]['splits']))\n",
    "    \n",
    "    splits.drop(columns = rename_dict[sum_level]['cols'], inplace= True)\n",
    "    \n",
    "    # combine the new dataframe with the previous one\n",
    "    df = pd.concat([df, tracts], axis= 1)\n",
    "    df = pd.concat([df, splits], axis= 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def data_census_pull(acs, year, sum_level, list_of_states, table_type, census_attributes):\n",
    "    \"\"\"\n",
    "    This function pulls data from the US census.  This allows to combine multiple states, which are pulled\n",
    "    based on a specific summary level\n",
    "    \n",
    "    \"\"\"\n",
    "    # create dataframe that will store the resulting query\n",
    "    census_df = pd.DataFrame()\n",
    "    \n",
    "    # let's doing our magic!! let's start pulling our census data\n",
    "    for state in list_of_states:\n",
    "        \n",
    "        # set the geo finding per summary level\n",
    "        census_geo_dict = {140: censusdata.censusgeo([('state', state), ('county', '*'), ('tract', '*')]),\n",
    "                           50: censusdata.censusgeo([('state', state), ('county', '*')]),\n",
    "                           40: censusdata.censusgeo([('state', state)])}\n",
    "    \n",
    "        # pull the data based on the summary level\n",
    "        region_census = tract_formatter(censusdata.download(acs, year, census_geo_dict[sum_level],\n",
    "                                                census_attributes, tabletype= table_type), sum_level)\n",
    "        census_df = pd.concat([census_df, region_census])\n",
    "          \n",
    "            \n",
    "    return census_df\n",
    "    \n",
    "\n",
    "def create_and_format_excel(acs, year, census_df, logic_list, sum_level):\n",
    "    \"\"\"\n",
    "    This function creates an Excel file where the resulting dataframes will be pasted.\n",
    "    Then, the data is formatted based on our color palette\n",
    "    \"\"\"\n",
    "    \n",
    "    ## INITIAL SET UP\n",
    "    # create date object and output folder, if necessary\n",
    "    today_date = time.strftime('%Y%m%d')\n",
    "    today_date_display = time.strftime('%m-%d-%Y')\n",
    "    \n",
    "    if not os.path.exists('output'):\n",
    "        os.mkdir('output')\n",
    "    \n",
    "    # create Excel file and its corresponding tabs\n",
    "    excel_file_census = os.path.join('output','census_data_formatter_{}.xlsx'.format(today_date))\n",
    "    writer = pd.ExcelWriter(excel_file_census, engine= 'xlsxwriter')\n",
    "    workbook = writer.book\n",
    "    \n",
    "    worksheet1 = workbook.add_worksheet('census_data')\n",
    "    worksheet2 = workbook.add_worksheet('logic')\n",
    "    \n",
    "    writer.sheets['census_data'] = worksheet1\n",
    "    writer.sheets['logic'] = worksheet2\n",
    "       \n",
    "    ## FORMAT TABS\n",
    "    # set formats for the dataframe.\n",
    "    title_format = workbook.add_format({'bold': True,\n",
    "                                        'italic': True,\n",
    "                                        'font_size': 20, \n",
    "                                        'font_color': '#007377'})\n",
    "    \n",
    "    notes_format = workbook.add_format({'bold': True,\n",
    "                                        'underline': True,\n",
    "                                        'font_size': 13})\n",
    "    \n",
    "    comments_format = workbook.add_format({'italic': True,\n",
    "                                          'font_size': 13})\n",
    "    \n",
    "    header_format = workbook.add_format({'bold': True,\n",
    "                                        'text_wrap': True,\n",
    "                                        'align': 'center',\n",
    "                                        'valign': 'top',\n",
    "                                        'font_size': 11,\n",
    "                                        'font_color': '#e7e6e6',\n",
    "                                        'fg_color': '#007377',\n",
    "                                        'border': 1})\n",
    "    \n",
    "    # define columns width and comments for tab CENSUS_DATA\n",
    "    worksheet1.set_column('A:A', 97)\n",
    "    worksheet1.set_column('B:V', 17)\n",
    "    worksheet1.set_column('W:Y', 22)\n",
    "    \n",
    "    worksheet1.write('A3', 'Census Data Extraction Outcome', title_format)\n",
    "    worksheet1.write('A5', 'Notes:', notes_format)\n",
    "    worksheet1.write('A6', 'The data pulled is from the American Community Survey ({}) for the year {}. Data pull date: {}'.format(acs.upper(), year, today_date_display), comments_format)\n",
    "    worksheet1.write('A7', 'Summary Level: {}'.format(sum_level), comments_format)\n",
    "    \n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(census_df.columns.values):\n",
    "        worksheet1.write(9, col_num, value, header_format)\n",
    "    \n",
    "    # define columns width and comments for tab LOGIC\n",
    "    worksheet2.set_column('A:D', 37)\n",
    "    worksheet2.set_column('E:E', 100)\n",
    "    \n",
    "    worksheet2.write('A3', 'Census Data Logic', title_format)\n",
    "    worksheet2.write('A5', 'Notes:', notes_format)\n",
    "    worksheet2.write('A6', 'The following details the equivalencies between the census columns and our naming convention', comments_format)\n",
    "    worksheet2.write('A7', 'Summary Level: {}'.format(sum_level), comments_format)\n",
    "    \n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(logic_list.columns.values):\n",
    "        worksheet2.write(9, col_num, value, header_format)\n",
    "    \n",
    "    ## PLACE DATAFRAMES AND FORMATS IN THE EXCEL OBJECT\n",
    "    census_df.to_excel(writer, sheet_name= 'census_data', index= False, startrow = 10, startcol= 0, header= False)\n",
    "    logic_list.to_excel(writer, sheet_name= 'logic', index= False, startrow = 10, startcol= 0, header= False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set parameters and create document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of States:    state_name state_number\n",
      "0   Illinois           17\n",
      "\n",
      "\n",
      "\n",
      "Extracting the following parameters: \n",
      "\n",
      "\n",
      "\n",
      "ACS:  acs5\n",
      "Year:  2019\n",
      "Summary Level:  140\n",
      "Frly:  GIS Name\n",
      "Table Type:  detail\n",
      "\n",
      "\n",
      "\n",
      "Document created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ############################# PART 1: SET PARAMETERS ##################################\n",
    "    \n",
    "    # define the file name. this is the file where parameters, states and logic are stored\n",
    "    file_name = 'GIS_Census_Index.xlsx'\n",
    "    \n",
    "    # read tabs \n",
    "    state_list = state_list(file_name)\n",
    "    print('List of States: ', state_list)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    acs, year, sum_level, frly, table_type = params_tupple(file_name)\n",
    "    print('Extracting the following parameters: ')\n",
    "    print('\\n\\n')\n",
    "    print('ACS: ', acs)\n",
    "    print('Year: ', year)\n",
    "    print('Summary Level: ', sum_level)\n",
    "    print('Frly: ', frly)\n",
    "    print('Table Type: ', table_type)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    logic_list, human_dict, mngr_dict, gis_dict, census_attributes = logic_tab(file_name) \n",
    "    #print('Logic List: ', logic_list)\n",
    "    \n",
    "    # exit the script in case some information is missing. parameters and geographies are \n",
    "    # mandatory to produce the information needed by the GIS team\n",
    "    if (len(state_list) == 0) | (acs is None) | (year is None) | (logic_list.shape[0] == 0):\n",
    "        \n",
    "        sys.exit(\"Insuficient Information.  Please, review our Excel file and fill the gaps\")\n",
    "    \n",
    "    \n",
    "    ############################# PART 2: DATA PULL FROM CENSUS.ORG ########################\n",
    "    \n",
    "    # Define the list of states where the data will pulled. This will allow us to pull multiple states\n",
    "    # at the same time.  Currently (version 1.0), only 3 summary levels are going to be brought\n",
    "    list_of_states = list(state_list['state_number'])\n",
    "    \n",
    "    # create dataframe that will store the resulting query\n",
    "    census_df = data_census_pull(acs, year, sum_level, list_of_states, table_type, census_attributes)\n",
    "            \n",
    "    # Our analyst will NOT be particularly interested in having a dataframe with coded names, so\n",
    "    # we are changing the metadata\n",
    "    cols_dict = {'Schema Name': census_attributes,\n",
    "                 'Human Friendly Name': human_dict,\n",
    "                 'Mgr_Name': mngr_dict,\n",
    "                 'GIS Name': gis_dict}\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        census_df.rename(columns= cols_dict[frly], inplace= True)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    ############################# PART 3: CREATE EXCEL FILE FOR R&E ########################\n",
    "    create_and_format_excel(acs, year, census_df, logic_list, sum_level)\n",
    "    \n",
    "    print(\"Document created\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "census_env",
   "language": "python",
   "name": "census_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
